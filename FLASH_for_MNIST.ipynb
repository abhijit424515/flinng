{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLASH Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foreword\n",
    "We will be using $L$ hashtables; each with $K$-tuple rows. We will further limit each table to just $w$ rows which will mean that we will definitely get some extra collisions in that process. Moreover, we will further allocate them reservoirs from a global pool of reservoirs. We will again get collisions when we start allocating shared reservoirs between multiple tables. However, we are given guarantees by the main paper so we can rest assured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing helpful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import struct\n",
    "import math\n",
    "import gzip\n",
    "\n",
    "def fullprint(*args, **kwargs):\n",
    "  from pprint import pprint\n",
    "  import numpy\n",
    "  opt = numpy.get_printoptions()\n",
    "  numpy.set_printoptions(threshold=numpy.inf)\n",
    "  pprint(*args, **kwargs)\n",
    "  numpy.set_printoptions(**opt)\n",
    "\n",
    "global L, w, K, R_total, R_per_table, R_shared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will initialise the two structures that are important to be global. The set of hash tables and the reservoirs they access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialization\n",
    "def create_Tables(N, Empty = np.nan): # all variables it creates are global\n",
    "    \"\"\"\n",
    "        N = Dimension of input data\n",
    "        L = Number of tables\n",
    "        w = length of each table\n",
    "        K = width of each row\n",
    "    \"\"\"\n",
    "    global Tables, a_array, b_array, perm_function\n",
    "    Tables = np.empty([L, w]) * Empty\n",
    "    a_array = np.zeros([L, K])\n",
    "    b_array = np.zeros([L, 1])\n",
    "    perm_function = np.zeros([L, N]) # Each table owns its own permutation function\n",
    "    for i in range(L): # For each table\n",
    "        a_array[i] = np.random.normal(0, 1, K)\n",
    "        b_array[i] = np.random.uniform(0, w)\n",
    "        perm_function[i] = np.random.permutation(np.arange(N))\n",
    "    perm_function = perm_function.astype(int)\n",
    "\n",
    "def create_Reservoirs(): # this will be initialised with R empty values and newer entries would be appended to each row\n",
    "    global Reservoir\n",
    "    Reservoir = [[] for _ in range(R_total)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will have some helper functions for the main algorithm.\n",
    "\n",
    "### DOPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DOPH_for_Lth_table(Datapoint, K, N, table_num, C = -1):\n",
    "    \"\"\"\n",
    "    Datapoint : Data (will be converted to binary and then it will be zero-padded till it has size N)\n",
    "    N : Size of Datapoint (Should be the maximum size possible for this format)\n",
    "    K : Size of output of one table of LSH\n",
    "    \"\"\"\n",
    "    if N%K != 0:\n",
    "        N = N + K - N%K # Made N a multiple of K\n",
    "    \n",
    "    # print(f\"Datapoint as is seen in {table_num}th table = {Datapoint}\")\n",
    "    binary_array = []\n",
    "    for coordinate in Datapoint:\n",
    "        binary_string = bin(coordinate)[2:]  # Convert coordinate to binary\n",
    "        binary_string = binary_string.zfill(8)  # Extend to 8 bits\n",
    "        binary_array.extend(list(binary_string))  # Concatenate to the array\n",
    "\n",
    "    binary_array = np.array(binary_array, dtype=int)  # Convert the array to numpy array\n",
    "\n",
    "    permuted_array = [binary_array[perm_function[table_num][i]] for i in range(N)]  # Permute the array according to the permutation function of that table\n",
    "    divided_arrays = np.reshape(permuted_array, (K, N//K)) # each of the rows now is one of the chunks\n",
    "    hash_tuple = np.zeros(K)\n",
    "    for i in range(K):\n",
    "        if np.max(divided_arrays[i]) < 1:\n",
    "            hash_tuple[i] = C\n",
    "        else:\n",
    "            hash_tuple[i] = np.nonzero(divided_arrays[i])[0][0]\n",
    "    # hash_tuple = [next((i for i, val in enumerate(row) if val != '0'), C) for row in divided_arrays] # Basically it chooses the first non-zero element in each row; if not found, it assigns it C\n",
    "    # print(f\"before rotation, hash_tuple looked in {table_num} as = \", hash_tuple)\n",
    "    for i in range(len(hash_tuple)):\n",
    "        if hash_tuple[i] == C:\n",
    "            j = (i + 1) % len(hash_tuple)\n",
    "            while j != i:\n",
    "                if hash_tuple[j] != C:\n",
    "                    hash_tuple[i] = hash_tuple[j] + ((j - i)% len(hash_tuple)) * C\n",
    "                    break\n",
    "                j = (j + 1) % len(hash_tuple)\n",
    "    # print(f\"shape of the hash_tuple in the {table_num}th table is = \",np.shape(hash_tuple))\n",
    "    # print(f\"hash_tuple for this image in the {table_num}th table is = \", hash_tuple)\n",
    "    return hash_tuple\n",
    "\n",
    "def DOPH(Datapoint, K, N, C = -1): # Does it for each of the tables\n",
    "    hash_tuples = np.empty([1, K]) # First row is empty\n",
    "    for i in range(L):\n",
    "        hash_tuples = np.vstack([hash_tuples, DOPH_for_Lth_table(Datapoint, K, N, i, C)])\n",
    "    return np.delete(hash_tuples, (0), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping the K-tuples to addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MapKHashesToAddress(Hash_tuple, Table_num):\n",
    "    # print(\"a_array's size = \", np.shape(a_array[Table_num]))\n",
    "    # print(\"Hash_tuple's size = \", np.shape(Hash_tuple))\n",
    "    # print(\"Final value = \", np.dot(Hash_tuple, a_array[Table_num]) + b_array[Table_num])\n",
    "    Key = np.floor(int(np.dot(Hash_tuple, a_array[Table_num]) + b_array[Table_num]) % w)\n",
    "    # print(\"Pakka final key = \")\n",
    "    return Key.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reservoir Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReservoirSampling(R, Stream):\n",
    "    Reservoir = np.zeros(R)\n",
    "    m = len(Stream)\n",
    "    \n",
    "    for i in range(R):\n",
    "        Reservoir[i] = Stream[i]\n",
    "    \n",
    "    for i in range(R, m):\n",
    "        j = random.randint(0, i)\n",
    "        if j < R:\n",
    "            Reservoir[j] = Stream[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AllocateReservoir(table_num): # such a search based approach is only feasible for small R_per_tables\n",
    "    # print(\"I am trying to allocate reservoir\")\n",
    "    start_index = table_num * R_per_table\n",
    "    end_index = (table_num + 1) * R_per_table\n",
    "    # print(f\"start index = {start_index}\")\n",
    "    # print(f\"end index = {end_index}\")\n",
    "    for i in range(start_index, end_index):\n",
    "        if Reservoir[i] == []:\n",
    "            # print(\"Reservoir selected is\", i)\n",
    "            return i # Thus the first empty index is returned\n",
    "    # print(\"Private Reservoir is exhausted\")\n",
    "    return -1  # Return -1 if no empty index is found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Algorithm 2 The Adding Phase\n",
    "# def Add(DataPoint, table_num, Key, Empty=np.nan):\n",
    "#     if Tables[table_num][Key] == Empty: # If that address is nascent\n",
    "#         Tables[table_num][Key] = AllocateReservoir(table_num) # We will allocate based on the table number; it will try to allocate in the private reservoir of that table and then in the global shared ones.\n",
    "#         ReservoirCounter = 0\n",
    "#     Rand = random.randint(0, ReservoirCounter)\n",
    "#     if Rand < R:\n",
    "#         Reservoir[Rand] = DataPoint\n",
    "#     ReservoirCounter += 1\n",
    "\n",
    "## Above was the implementation according to the pseudo-code. Don't see the point in doing so\n",
    "def Add(label, table_num, Key, Empty=np.nan):\n",
    "    # print(f\"Key that has be to added to {table_num}\")\n",
    "    # print(Key)\n",
    "    # print(Tables[table_num][Key])\n",
    "    if np.isnan(Tables[table_num][Key]): # If that address is nascent\n",
    "        Pointer_to_reservoir = AllocateReservoir(table_num) # We will allocate based on the table number; it will try to allocate in the private reservoir of that table and then in the global shared ones.\n",
    "        if Pointer_to_reservoir == -1: # If no space is available in the reservoir\n",
    "            # print(\"We accessed global reservoirs\")\n",
    "            Pointer_to_reservoir = random.randint(L * R_per_table, R_total)\n",
    "        Tables[table_num][Key] = Pointer_to_reservoir\n",
    "    else:\n",
    "        # print(\"I am here\")\n",
    "        Pointer_to_reservoir = Tables[table_num][Key]\n",
    "    # print(\"pointer to reservoir is \",Pointer_to_reservoir)\n",
    "    Reservoir[int(Pointer_to_reservoir)].append(label)\n",
    "\n",
    "def Adding_Phase(DataPoints, Labels, N):\n",
    "    \"\"\"\n",
    "        N = Dimension of input data\n",
    "        DataPoints = Set of data (each row is a datapoint)\n",
    "        Labels = The unique identifier for each of the datapoints\n",
    "    \"\"\"\n",
    "    for i in range(len(DataPoints)): # parse each row\n",
    "        Hash_tuples = DOPH(DataPoints[i], K, N) # For each datapoint, returns back K hashes for each table as rows\n",
    "        # print(\"Hashtuples for this image is\", Hash_tuples)\n",
    "        for j in range(L):\n",
    "            Key = MapKHashesToAddress(Hash_tuples[j], j) # For th ith datapoint, get the key for the jth table\n",
    "            # print(Key)\n",
    "            Add(Labels[i], j, Key) # Add this datapoint to the ith table at the key\n",
    "        print(f\"{i}th Image done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Algorithm 3 The Querying Phase\n",
    "def Querying_Phase(QueryPoints, TopK, N):\n",
    "    results = []\n",
    "    for QueryPoint in QueryPoints: # we will just deal with each of the queries one by one (in parallel with a loop)\n",
    "        Hash_tuples = DOPH(QueryPoint, K, N) # get L rows of K-tuple (one K-tuple for each table)\n",
    "        A = []\n",
    "        for i in range(L):\n",
    "            Key = (MapKHashesToAddress(Hash_tuples[i], i)) # we find the key for the ith table of the query point\n",
    "            A.extend(Reservoir[int(Tables[i][Key])]) # append all of the labels in the reservoir at that location\n",
    "        # print(A)\n",
    "        i = KSelect(A, TopK) \n",
    "        results.append(i)\n",
    "    return results\n",
    "\n",
    "def KSelect(A, TopK):\n",
    "    A.sort() # Sorting the pointers\n",
    "    KV_Pair = CountFrequency(A)\n",
    "    sorted_KV_Pair = sorted(KV_Pair.items(), key=lambda x: x[1], reverse=True) # Boht sus\n",
    "    return sorted_KV_Pair[:TopK]\n",
    "\n",
    "\n",
    "def CountFrequency(A):\n",
    "    KV_Pair = {}\n",
    "    for label in A:\n",
    "        if label in KV_Pair:\n",
    "            KV_Pair[label] += 1\n",
    "        else:\n",
    "            KV_Pair[label] = 1\n",
    "    return KV_Pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing it just because it looked sus af."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('apple', 3), ('god', 3), ('cat', 2)]\n"
     ]
    }
   ],
   "source": [
    "set_A = ['apple', 'god', 'don', 'don', 'elephant', 'cat', 'apple', 'god', 'france', 'apple', 'god', 'cat']\n",
    "print(KSelect(set_A, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executable code\n",
    "## Setting the stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = int(5)  # Number of tables\n",
    "K = int(2)  # Number of hash functions per row\n",
    "w = int(100) # Size of each table\n",
    "R_total = int(2000) # Number of reservoirs\n",
    "R_per_table = int(10)\n",
    "R_shared = R_total - L * R_per_table # Each of the tables only gets 5 reservoirs exlcusively; others are shared\n",
    "\n",
    "if R_shared < 0:\n",
    "    print(\"Error: Not enough global reservoirs\")\n",
    "    exit()\n",
    "\n",
    "N = int(28 * 28 * 8) # Depends on the type of data really"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.17291287 -0.43420084]\n",
      " [ 0.13758854  0.27805583]\n",
      " [ 1.01965976 -0.0040841 ]\n",
      " [ 0.04457535 -0.50631528]\n",
      " [ 0.14397719 -0.08409342]]\n",
      "[[15.89380679]\n",
      " [82.99317413]\n",
      " [90.40559137]\n",
      " [17.29448788]\n",
      " [66.18589226]]\n"
     ]
    }
   ],
   "source": [
    "create_Tables(N) # Empty tables as well as the corresponding mapping functions have been initialized\n",
    "create_Reservoirs() # Empty reservoirs have been initialized\n",
    "\n",
    "print(a_array)\n",
    "print(b_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Datapoints\n",
    "### MNIST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2051 60000 28 28\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "def read_mnist(filename, number_of_images, kitna_chahiye):\n",
    "    with open(filename, 'rb') as file:\n",
    "        magic_number = struct.unpack('>I', file.read(4))[0]\n",
    "        number_of_image = struct.unpack('>I', file.read(4))[0]\n",
    "        n_rows = struct.unpack('>I', file.read(4))[0]\n",
    "        n_cols = struct.unpack('>I', file.read(4))[0]\n",
    "        print(magic_number, number_of_image, n_rows, n_cols)\n",
    "        data = []\n",
    "        for i in range(kitna_chahiye):\n",
    "            images = []\n",
    "            for r in range(n_rows):\n",
    "                row = []\n",
    "                for c in range(n_cols):\n",
    "                    temp = struct.unpack('>B', file.read(1))[0]\n",
    "                    row.append(float(temp))\n",
    "                images.extend(row)\n",
    "            data.extend(images)\n",
    "        data = np.array(data)\n",
    "        data=data.reshape(kitna_chahiye, 28 * 28)\n",
    "        return data\n",
    "\n",
    "def read_mnist_label(file_name, num_to_read, kitna_chahiye):\n",
    "    with open(file_name, 'rb') as file:\n",
    "        # Read the metadata\n",
    "        magic_number = struct.unpack('>I', file.read(4))[0]\n",
    "        number_of_images = struct.unpack('>I', file.read(4))[0]\n",
    "\n",
    "        \n",
    "        labels = np.zeros(kitna_chahiye, dtype=np.int32)\n",
    "\n",
    "        for i in range(kitna_chahiye):\n",
    "            temp = struct.unpack('>B', file.read(1))[0]\n",
    "            labels[i] = temp\n",
    " \n",
    "    return labels\n",
    "# Define file paths\n",
    "\n",
    "train_images_file = \"MNIST_Data/train-images-idx3-ubyte\"\n",
    "train_labels_file = \"MNIST_Data/train-labels-idx1-ubyte\"\n",
    "\n",
    "# Define parameters\n",
    "kitna_chahiye = 500\n",
    "image_size = 28 * 28  # MNIST images are 28x28 pixels\n",
    "\n",
    "data=[]\n",
    "data=read_mnist(train_images_file, 60000, kitna_chahiye)\n",
    "labels= read_mnist_label(train_labels_file, 60000, kitna_chahiye)\n",
    "\n",
    "data = data.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = data[450].reshape(28, 28)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[450]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Data\n",
    "This is data we know trends about thus would allow us to test the accuracy of our algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L_star = 10\n",
    "# N_star = 16\n",
    "# perm_function_lmao = np.zeros([L_star, N_star]) # Each table owns its own permutation function\n",
    "# for i in range(L_star): # For each table\n",
    "#     perm_function_lmao[i] = np.random.permutation(np.arange(N_star))\n",
    "# perm_function_lmao = perm_function_lmao.astype(int)\n",
    "# print(perm_function_lmao)\n",
    "\n",
    "# Datapoint = [15, 2]\n",
    "# binary_array = []\n",
    "# for coordinate in Datapoint:\n",
    "#     binary_string = bin(coordinate)[2:]  # Convert coordinate to binary\n",
    "#     binary_string = binary_string.zfill(8)  # Extend to 8 bits\n",
    "#     binary_array.extend(list(binary_string))  # Concatenate to the array\n",
    "\n",
    "# binary_array = np.array(binary_array, dtype=int)  # Convert the array to numpy array\n",
    "# print(binary_array)\n",
    "# permuted_array = [binary_array[perm_function_lmao[0][i]] for i in range(N_star)]\n",
    "# print(permuted_array)\n",
    "# print(28 * 28 * 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Datapoints to the HashTable & Reservoirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43732/2824102134.py:5: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  Key = np.floor(int(np.dot(Hash_tuple, a_array[Table_num]) + b_array[Table_num]) % w)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th Image done.\n",
      "1th Image done.\n",
      "2th Image done.\n",
      "3th Image done.\n",
      "4th Image done.\n",
      "5th Image done.\n",
      "6th Image done.\n",
      "7th Image done.\n",
      "8th Image done.\n",
      "9th Image done.\n",
      "10th Image done.\n",
      "11th Image done.\n",
      "12th Image done.\n",
      "13th Image done.\n",
      "14th Image done.\n",
      "15th Image done.\n",
      "16th Image done.\n",
      "17th Image done.\n",
      "18th Image done.\n",
      "19th Image done.\n",
      "20th Image done.\n",
      "21th Image done.\n",
      "22th Image done.\n",
      "23th Image done.\n",
      "24th Image done.\n",
      "25th Image done.\n",
      "26th Image done.\n",
      "27th Image done.\n",
      "28th Image done.\n",
      "29th Image done.\n",
      "30th Image done.\n",
      "31th Image done.\n",
      "32th Image done.\n",
      "33th Image done.\n",
      "34th Image done.\n",
      "35th Image done.\n",
      "36th Image done.\n",
      "37th Image done.\n",
      "38th Image done.\n",
      "39th Image done.\n",
      "40th Image done.\n",
      "41th Image done.\n",
      "42th Image done.\n",
      "43th Image done.\n",
      "44th Image done.\n",
      "45th Image done.\n",
      "46th Image done.\n",
      "47th Image done.\n",
      "48th Image done.\n",
      "49th Image done.\n",
      "50th Image done.\n",
      "51th Image done.\n",
      "52th Image done.\n",
      "53th Image done.\n",
      "54th Image done.\n",
      "55th Image done.\n",
      "56th Image done.\n",
      "57th Image done.\n",
      "58th Image done.\n",
      "59th Image done.\n",
      "60th Image done.\n",
      "61th Image done.\n",
      "62th Image done.\n",
      "63th Image done.\n",
      "64th Image done.\n",
      "65th Image done.\n",
      "66th Image done.\n",
      "67th Image done.\n",
      "68th Image done.\n",
      "69th Image done.\n",
      "70th Image done.\n",
      "71th Image done.\n",
      "72th Image done.\n",
      "73th Image done.\n",
      "74th Image done.\n",
      "75th Image done.\n",
      "76th Image done.\n",
      "77th Image done.\n",
      "78th Image done.\n",
      "79th Image done.\n",
      "80th Image done.\n",
      "81th Image done.\n",
      "82th Image done.\n",
      "83th Image done.\n",
      "84th Image done.\n",
      "85th Image done.\n",
      "86th Image done.\n",
      "87th Image done.\n",
      "88th Image done.\n",
      "89th Image done.\n",
      "90th Image done.\n",
      "91th Image done.\n",
      "92th Image done.\n",
      "93th Image done.\n",
      "94th Image done.\n",
      "95th Image done.\n",
      "96th Image done.\n",
      "97th Image done.\n",
      "98th Image done.\n",
      "99th Image done.\n",
      "100th Image done.\n",
      "101th Image done.\n",
      "102th Image done.\n",
      "103th Image done.\n",
      "104th Image done.\n",
      "105th Image done.\n",
      "106th Image done.\n",
      "107th Image done.\n",
      "108th Image done.\n",
      "109th Image done.\n",
      "110th Image done.\n",
      "111th Image done.\n",
      "112th Image done.\n",
      "113th Image done.\n",
      "114th Image done.\n",
      "115th Image done.\n",
      "116th Image done.\n",
      "117th Image done.\n",
      "118th Image done.\n",
      "119th Image done.\n",
      "120th Image done.\n",
      "121th Image done.\n",
      "122th Image done.\n",
      "123th Image done.\n",
      "124th Image done.\n",
      "125th Image done.\n",
      "126th Image done.\n",
      "127th Image done.\n",
      "128th Image done.\n",
      "129th Image done.\n",
      "130th Image done.\n",
      "131th Image done.\n",
      "132th Image done.\n",
      "133th Image done.\n",
      "134th Image done.\n",
      "135th Image done.\n",
      "136th Image done.\n",
      "137th Image done.\n",
      "138th Image done.\n",
      "139th Image done.\n",
      "140th Image done.\n",
      "141th Image done.\n",
      "142th Image done.\n",
      "143th Image done.\n",
      "144th Image done.\n",
      "145th Image done.\n",
      "146th Image done.\n",
      "147th Image done.\n",
      "148th Image done.\n",
      "149th Image done.\n",
      "150th Image done.\n",
      "151th Image done.\n",
      "152th Image done.\n",
      "153th Image done.\n",
      "154th Image done.\n",
      "155th Image done.\n",
      "156th Image done.\n",
      "157th Image done.\n",
      "158th Image done.\n",
      "159th Image done.\n",
      "160th Image done.\n",
      "161th Image done.\n",
      "162th Image done.\n",
      "163th Image done.\n",
      "164th Image done.\n",
      "165th Image done.\n",
      "166th Image done.\n",
      "167th Image done.\n",
      "168th Image done.\n",
      "169th Image done.\n",
      "170th Image done.\n",
      "171th Image done.\n",
      "172th Image done.\n",
      "173th Image done.\n",
      "174th Image done.\n",
      "175th Image done.\n",
      "176th Image done.\n",
      "177th Image done.\n",
      "178th Image done.\n",
      "179th Image done.\n",
      "180th Image done.\n",
      "181th Image done.\n",
      "182th Image done.\n",
      "183th Image done.\n",
      "184th Image done.\n",
      "185th Image done.\n",
      "186th Image done.\n",
      "187th Image done.\n",
      "188th Image done.\n",
      "189th Image done.\n",
      "190th Image done.\n",
      "191th Image done.\n",
      "192th Image done.\n",
      "193th Image done.\n",
      "194th Image done.\n",
      "195th Image done.\n",
      "196th Image done.\n",
      "197th Image done.\n",
      "198th Image done.\n",
      "199th Image done.\n",
      "200th Image done.\n",
      "201th Image done.\n",
      "202th Image done.\n",
      "203th Image done.\n",
      "204th Image done.\n",
      "205th Image done.\n",
      "206th Image done.\n",
      "207th Image done.\n",
      "208th Image done.\n",
      "209th Image done.\n",
      "210th Image done.\n",
      "211th Image done.\n",
      "212th Image done.\n",
      "213th Image done.\n",
      "214th Image done.\n",
      "215th Image done.\n",
      "216th Image done.\n",
      "217th Image done.\n",
      "218th Image done.\n",
      "219th Image done.\n",
      "220th Image done.\n",
      "221th Image done.\n",
      "222th Image done.\n",
      "223th Image done.\n",
      "224th Image done.\n",
      "225th Image done.\n",
      "226th Image done.\n",
      "227th Image done.\n",
      "228th Image done.\n",
      "229th Image done.\n",
      "230th Image done.\n",
      "231th Image done.\n",
      "232th Image done.\n",
      "233th Image done.\n",
      "234th Image done.\n",
      "235th Image done.\n",
      "236th Image done.\n",
      "237th Image done.\n",
      "238th Image done.\n",
      "239th Image done.\n",
      "240th Image done.\n",
      "241th Image done.\n",
      "242th Image done.\n",
      "243th Image done.\n",
      "244th Image done.\n",
      "245th Image done.\n",
      "246th Image done.\n",
      "247th Image done.\n",
      "248th Image done.\n",
      "249th Image done.\n",
      "250th Image done.\n",
      "251th Image done.\n",
      "252th Image done.\n",
      "253th Image done.\n",
      "254th Image done.\n",
      "255th Image done.\n",
      "256th Image done.\n",
      "257th Image done.\n",
      "258th Image done.\n",
      "259th Image done.\n",
      "260th Image done.\n",
      "261th Image done.\n",
      "262th Image done.\n",
      "263th Image done.\n",
      "264th Image done.\n",
      "265th Image done.\n",
      "266th Image done.\n",
      "267th Image done.\n",
      "268th Image done.\n",
      "269th Image done.\n",
      "270th Image done.\n",
      "271th Image done.\n",
      "272th Image done.\n",
      "273th Image done.\n",
      "274th Image done.\n",
      "275th Image done.\n",
      "276th Image done.\n",
      "277th Image done.\n",
      "278th Image done.\n",
      "279th Image done.\n",
      "280th Image done.\n",
      "281th Image done.\n",
      "282th Image done.\n",
      "283th Image done.\n",
      "284th Image done.\n",
      "285th Image done.\n",
      "286th Image done.\n",
      "287th Image done.\n",
      "288th Image done.\n",
      "289th Image done.\n",
      "290th Image done.\n",
      "291th Image done.\n",
      "292th Image done.\n",
      "293th Image done.\n",
      "294th Image done.\n",
      "295th Image done.\n",
      "296th Image done.\n",
      "297th Image done.\n",
      "298th Image done.\n",
      "299th Image done.\n",
      "300th Image done.\n",
      "301th Image done.\n",
      "302th Image done.\n",
      "303th Image done.\n",
      "304th Image done.\n",
      "305th Image done.\n",
      "306th Image done.\n",
      "307th Image done.\n",
      "308th Image done.\n",
      "309th Image done.\n",
      "310th Image done.\n",
      "311th Image done.\n",
      "312th Image done.\n",
      "313th Image done.\n",
      "314th Image done.\n",
      "315th Image done.\n",
      "316th Image done.\n",
      "317th Image done.\n",
      "318th Image done.\n",
      "319th Image done.\n",
      "320th Image done.\n",
      "321th Image done.\n",
      "322th Image done.\n",
      "323th Image done.\n",
      "324th Image done.\n",
      "325th Image done.\n",
      "326th Image done.\n",
      "327th Image done.\n",
      "328th Image done.\n",
      "329th Image done.\n",
      "330th Image done.\n",
      "331th Image done.\n",
      "332th Image done.\n",
      "333th Image done.\n",
      "334th Image done.\n",
      "335th Image done.\n",
      "336th Image done.\n",
      "337th Image done.\n",
      "338th Image done.\n",
      "339th Image done.\n",
      "340th Image done.\n",
      "341th Image done.\n",
      "342th Image done.\n",
      "343th Image done.\n",
      "344th Image done.\n",
      "345th Image done.\n",
      "346th Image done.\n",
      "347th Image done.\n",
      "348th Image done.\n",
      "349th Image done.\n",
      "350th Image done.\n",
      "351th Image done.\n",
      "352th Image done.\n",
      "353th Image done.\n",
      "354th Image done.\n",
      "355th Image done.\n",
      "356th Image done.\n",
      "357th Image done.\n",
      "358th Image done.\n",
      "359th Image done.\n",
      "360th Image done.\n",
      "361th Image done.\n",
      "362th Image done.\n",
      "363th Image done.\n",
      "364th Image done.\n",
      "365th Image done.\n",
      "366th Image done.\n",
      "367th Image done.\n",
      "368th Image done.\n",
      "369th Image done.\n",
      "370th Image done.\n",
      "371th Image done.\n",
      "372th Image done.\n",
      "373th Image done.\n",
      "374th Image done.\n",
      "375th Image done.\n",
      "376th Image done.\n",
      "377th Image done.\n",
      "378th Image done.\n",
      "379th Image done.\n",
      "380th Image done.\n",
      "381th Image done.\n",
      "382th Image done.\n",
      "383th Image done.\n",
      "384th Image done.\n",
      "385th Image done.\n",
      "386th Image done.\n",
      "387th Image done.\n",
      "388th Image done.\n",
      "389th Image done.\n",
      "390th Image done.\n",
      "391th Image done.\n",
      "392th Image done.\n",
      "393th Image done.\n",
      "394th Image done.\n",
      "395th Image done.\n",
      "396th Image done.\n",
      "397th Image done.\n",
      "398th Image done.\n",
      "399th Image done.\n",
      "400th Image done.\n",
      "401th Image done.\n",
      "402th Image done.\n",
      "403th Image done.\n",
      "404th Image done.\n",
      "405th Image done.\n",
      "406th Image done.\n",
      "407th Image done.\n",
      "408th Image done.\n",
      "409th Image done.\n",
      "410th Image done.\n",
      "411th Image done.\n",
      "412th Image done.\n",
      "413th Image done.\n",
      "414th Image done.\n",
      "415th Image done.\n",
      "416th Image done.\n",
      "417th Image done.\n",
      "418th Image done.\n",
      "419th Image done.\n",
      "420th Image done.\n",
      "421th Image done.\n",
      "422th Image done.\n",
      "423th Image done.\n",
      "424th Image done.\n",
      "425th Image done.\n",
      "426th Image done.\n",
      "427th Image done.\n",
      "428th Image done.\n",
      "429th Image done.\n",
      "430th Image done.\n",
      "431th Image done.\n",
      "432th Image done.\n",
      "433th Image done.\n",
      "434th Image done.\n",
      "435th Image done.\n",
      "436th Image done.\n",
      "437th Image done.\n",
      "438th Image done.\n",
      "439th Image done.\n",
      "440th Image done.\n",
      "441th Image done.\n",
      "442th Image done.\n",
      "443th Image done.\n",
      "444th Image done.\n",
      "445th Image done.\n",
      "446th Image done.\n",
      "447th Image done.\n",
      "448th Image done.\n",
      "449th Image done.\n",
      "450th Image done.\n",
      "451th Image done.\n",
      "452th Image done.\n",
      "453th Image done.\n",
      "454th Image done.\n",
      "455th Image done.\n",
      "456th Image done.\n",
      "457th Image done.\n",
      "458th Image done.\n",
      "459th Image done.\n",
      "460th Image done.\n",
      "461th Image done.\n",
      "462th Image done.\n",
      "463th Image done.\n",
      "464th Image done.\n",
      "465th Image done.\n",
      "466th Image done.\n",
      "467th Image done.\n",
      "468th Image done.\n",
      "469th Image done.\n",
      "470th Image done.\n",
      "471th Image done.\n",
      "472th Image done.\n",
      "473th Image done.\n",
      "474th Image done.\n",
      "475th Image done.\n",
      "476th Image done.\n",
      "477th Image done.\n",
      "478th Image done.\n",
      "479th Image done.\n"
     ]
    }
   ],
   "source": [
    "Adding_Phase(data[:480], labels[:480], image_size * 8) # 8 bits per pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(1, 82), (3, 76), (2, 63), (9, 49), (0, 46)]]\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43732/2824102134.py:5: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  Key = np.floor(int(np.dot(Hash_tuple, a_array[Table_num]) + b_array[Table_num]) % w)\n"
     ]
    }
   ],
   "source": [
    "results = Querying_Phase([data[360]], 5, image_size * 8)\n",
    "print(results)\n",
    "print(labels[360])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the state\n",
    "#### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# np.save(\"hashtable_MNIST.npy\", Tables)\n",
    "# np.save(\"a_MNIST.npy\", a_array)\n",
    "# np.save(\"b_MNIST.npy\", b_array)\n",
    "# np.save(\"perm_function_MNIST.npy\", perm_function)\n",
    "# # Save the Reservoir list to a file\n",
    "# with open('reservoir_MNIST.pkl', 'wb') as f:\n",
    "#     pickle.dump(Reservoir, f)\n",
    "\n",
    "# # Save the variables using Pickle\n",
    "# with open('variables_MNIST.pkl', 'wb') as f:\n",
    "#     pickle.dump(K, f)\n",
    "#     pickle.dump(L, f)\n",
    "#     pickle.dump(w, f)\n",
    "#     pickle.dump(N, f)\n",
    "#     pickle.dump(R_per_table, f)\n",
    "#     pickle.dump(R_shared, f)\n",
    "#     pickle.dump(R_total, f)\n",
    "#     pickle.dump(Reservoir, f)\n",
    "#     pickle.dump(Tables, f)\n",
    "#     pickle.dump(a_array, f)\n",
    "#     pickle.dump(b_array, f)\n",
    "#     pickle.dump(data, f)\n",
    "#     pickle.dump(image_size, f)\n",
    "#     pickle.dump(kitna_chahiye, f)\n",
    "#     pickle.dump(labels, f)\n",
    "#     pickle.dump(perm_function, f)\n",
    "#     pickle.dump(Tables, f)\n",
    "#     pickle.dump(N, f)\n",
    "#     pickle.dump(labels, f)\n",
    "#     pickle.dump(perm_function, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the state\n",
    "#### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('reservoir_MNIST.pkl', 'rb') as f:\n",
    "#     Reservoir = pickle.load(f)\n",
    "\n",
    "# Tables = np.load(\"hashtable_MNIST.npy\")\n",
    "# a_array = np.load(\"a_MNIST.npy\")\n",
    "# b_array = np.load(\"b_MNIST.npy\")\n",
    "# perm_function = np.load(\"perm_function_MNIST.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "## R@K\n",
    "We will use K = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43732/2824102134.py:5: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  Key = np.floor(int(np.dot(Hash_tuple, a_array[Table_num]) + b_array[Table_num]) % w)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results aagaye\n",
      "0.75\n",
      "2.9597747325897217\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def evaluate_model_RK(data, labels, TopK):\n",
    "    start = time.time()\n",
    "    queried = np.random.choice(480, 100)\n",
    "    results = Querying_Phase(data[queried], TopK, image_size * 8)\n",
    "    print(\"results aagaye\")\n",
    "    counter = 0\n",
    "    labels_queried = labels[queried]\n",
    "    for i in range(len(results)):\n",
    "        neighbors = [t[0] for t in results[i]]\n",
    "        if labels_queried[i] in neighbors:\n",
    "            counter += 1\n",
    "    end = time.time()\n",
    "    return [counter/100, end-start]\n",
    "\n",
    "[recall_acc, timer] = evaluate_model_RK(data, labels, 4)\n",
    "print(recall_acc)\n",
    "print(timer)\n",
    "\n",
    "timer_list = np.load(\"timer_list.npy\")\n",
    "recall_acc_list = np.load(\"recall_acc_list.npy\")\n",
    "params_list = np.load(\"params_list.npy\")\n",
    "\n",
    "timer_list = np.append(timer_list, timer)\n",
    "recall_acc_list = np.append(recall_acc_list, recall_acc)\n",
    "params_list = np.append(params_list, [L, K])\n",
    "\n",
    "np.save(\"timer_list.npy\", timer_list)\n",
    "np.save(\"recall_acc_list.npy\", recall_acc_list)\n",
    "np.save(\"params_list.npy\", params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timer_list = np.array([])\n",
    "# recall_acc_list = np.array([])\n",
    "# params_list = np.array([])\n",
    "# np.save(\"timer_list.npy\", timer_list)\n",
    "# np.save(\"recall_acc_list.npy\", recall_acc_list)\n",
    "# np.save(\"params_list.npy\", params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25.  2. 25. 28. 25. 56.  5.  2.  5. 28.  5. 56.  5.  2.]\n"
     ]
    }
   ],
   "source": [
    "checking = np.load(\"params_list.npy\")\n",
    "print(checking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mega Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot([2, 28, 56], timer_list[3:], label = \"L = 5\")\n",
    "plt.plot([2, 28, 56], timer_list[:3], label = \"L = 25\")\n",
    "plt.title(\"Timing\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Query times\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot([2, 28, 56], recall_acc_list[3:], label = \"L = 5\")\n",
    "plt.plot([2, 28, 56], recall_acc_list[:3], label = \"L = 25\")\n",
    "plt.title(\"R@4\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Recall Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
